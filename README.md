# Project-1

I project one big data tools are used to perform analysis about datasets from wikipedia.

The analysis consists of answering six questions using Hive.

The questions are listed below:
  1. Which English wikipedia article got the most traffic on January 20, 2021?
  2. What English wikipedia article has the largest fraction of its readers follow an internal link to another wikipedia article?
  3. What series of wikipedia articles, starting with Hotel California, keeps the largest fraction of its readers clicking on internal links? 
  4. Find an example of an English wikipedia article that is relatively more popular in the Americas than elsewhere.
  5. Analyze how many users will see the average vandalized wikipedia page before the offending edit is reversed.
  6. What were the top ten most viewed wikipedia pages for each hour on January 20, 2021?
  
 Technologies used
  1. YARN
  2. HDFS
  3. Hive
  4. Hadoop Map Reduce
  5. Git + GitHub
  
  Dataset Links
    1. Pageviews Filtered to Human Traffic
        https://wikitech.wikimedia.org/wiki/Analytics/Data_Lake/Traffic/Pageviews
    2. Page Revision and User History
        https://wikitech.wikimedia.org/wiki/Analytics/Data_Lake/Edits/Mediawiki_history_dumps#Technical_Documentation
    3. Monthly Clickstream
        https://meta.wikimedia.org/wiki/Research:Wikipedia_clickstream
